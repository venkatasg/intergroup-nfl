{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98617c66-7386-4915-93ad-5d782b171959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomState(MT19937) at 0x178E73140"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import ipdb\n",
    "import re\n",
    "from glob import glob\n",
    "import json\n",
    "import csv\n",
    "import datetime as dt\n",
    "from copy import deepcopy\n",
    "from collections import Counter\n",
    "from difflib import SequenceMatcher\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa, aggregate_raters\n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "scaler = MaxAbsScaler()\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('chained_assignment',None)\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "from nltk.corpus import words\n",
    "word_list = words.words()\n",
    "\n",
    "# Set random seeds for reproducibility on a specific machine\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "np.random.RandomState(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eee27a61-7fe5-4f40-a08c-c24b75ae5e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = pd.read_csv('../../../data/gold_data.tsv', sep='\\t', quoting=csv.QUOTE_NONE, escapechar=\"\\\\\")\n",
    "gold.ref_expressions = gold.ref_expressions.apply(lambda x: eval(x))\n",
    "gold.ref_pos = gold.ref_pos.apply(lambda x: eval(x))\n",
    "gold.ref_tags = gold.ref_tags.apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7972bb8-08bc-4e60-80fe-28d9e9e41490",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = []\n",
    "files = glob('*annotation*.json')\n",
    "for file in files:\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        new_anns = json.load(f)\n",
    "        for f in new_anns:\n",
    "            f['user'] = file.split('-')[2][0]\n",
    "        annotations += new_anns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83fb7e4f-7da6-4694-a287-bc3e3e5c28db",
   "metadata": {},
   "outputs": [],
   "source": [
    "postinfo = pd.read_csv('../../../data/postInfo.tsv', sep='\\t')\n",
    "gameinfo = pd.read_csv('../../../data/gameInfo.tsv', sep='\\t')\n",
    "\n",
    "teaminfo = pd.read_csv('../../../data/nfl_teams.csv')\n",
    "teaminfo['team_name_short'] = teaminfo['team_name_short'].apply(lambda x: x.lower())\n",
    "\n",
    "teams = teaminfo['team_name_short'].values.tolist()\n",
    "subreddits = teaminfo['subreddit'].values.tolist()\n",
    "\n",
    "teams_to_subreddit = {teams[i]: subreddits[i] for i in range(32)}\n",
    "subreddit_to_teams = {subreddits[i]: teams[i] for i in range(32)}\n",
    "team_names_dict = {x: [x] for x in teams}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1cc446f-d98b-4854-943e-f27448bf26d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 1179/1179 [00:00<00:00, 29018.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1179, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_df = {'post_id': [], 'comment_id': [], 'tokenized_comment': [], 'tagged_comment': [], 'ref_expressions': [], 'ref_pos': [], 'ref_tags': [], 'user': [], 'confs': []}\n",
    "\n",
    "for ann in tqdm(annotations):\n",
    "    \n",
    "    edits = ann['edits']\n",
    "    # Sort it\n",
    "    edits.sort(key=(lambda x: x['input_idx'][0][0]))\n",
    "        \n",
    "    ann_df['post_id'].append(ann['post_id'])\n",
    "    ann_df['comment_id'].append(ann['comment_id'])\n",
    "    tokenized_comment = ann['source']\n",
    "    ann_df['tokenized_comment'].append(tokenized_comment)\n",
    "    ann_df['user'].append(ann['user'])\n",
    "    \n",
    "    tagged_comment = ''\n",
    "    ref_expressions = []\n",
    "    ref_pos = []\n",
    "    ref_tags = []\n",
    "    confs = []\n",
    "    \n",
    "    for ind, curr_edit in enumerate(edits):\n",
    "        # Figure out the referring expression for that edit\n",
    "        ref_expr = tokenized_comment[curr_edit['input_idx'][0][0]:curr_edit['input_idx'][0][1]]\n",
    "        \n",
    "        start_pos = curr_edit['input_idx'][0][0]\n",
    "        end_pos = curr_edit['input_idx'][0][1]\n",
    "        \n",
    "        ref_expressions.append(ref_expr)\n",
    "        ref_pos.append((curr_edit['input_idx'][0][0], end_pos))\n",
    "        \n",
    "        ref_tags.append('<' + curr_edit['category'] + '>')\n",
    "\n",
    "        # Get confidence scores\n",
    "        if curr_edit['annotation'] is not None:\n",
    "            # Need to check for conf, since I annotated with 'ref' without conf sometimes\n",
    "            if 'conf' in curr_edit['annotation'].keys():\n",
    "                # set_trace()\n",
    "                confs.append(int(curr_edit['annotation']['conf']['val'].split('_')[-1]))\n",
    "            else:\n",
    "                confs.append(5)\n",
    "        else:\n",
    "            confs.append(5)\n",
    "        \n",
    "        # Get the new tagged comment based on edit indices\n",
    "        if ind==0:\n",
    "            tagged_comment = tokenized_comment[:curr_edit['input_idx'][0][0]] + '<' + curr_edit['category'] + '>'\n",
    "            if len(edits)!=1:\n",
    "                next_edit = edits[ind+1]\n",
    "                tagged_comment += tokenized_comment[curr_edit['input_idx'][0][1]:next_edit['input_idx'][0][0]]\n",
    "            else:\n",
    "                tagged_comment += tokenized_comment[curr_edit['input_idx'][0][1]:]\n",
    "        elif ind!=len(edits)-1:\n",
    "            next_edit = edits[ind+1]\n",
    "            tagged_comment += '<' + curr_edit['category'] + '>' + tokenized_comment[curr_edit['input_idx'][0][1]:next_edit['input_idx'][0][0]]\n",
    "        else:\n",
    "            tagged_comment += '<' + curr_edit['category'] + '>' + tokenized_comment[curr_edit['input_idx'][0][1]:]\n",
    "    \n",
    "    ann_df['tagged_comment'].append(tagged_comment)\n",
    "    ann_df['ref_expressions'].append(ref_expressions)\n",
    "    ann_df['ref_tags'].append(ref_tags)\n",
    "    ann_df['ref_pos'].append(ref_pos)\n",
    "    if confs==[]:\n",
    "        confs = [5]\n",
    "    ann_df['confs'].append(confs)\n",
    "\n",
    "ann_df = pd.DataFrame(ann_df)\n",
    "ann_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d6c5423-334f-4922-a69f-99da0b710eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_df.tagged_comment = ann_df.tagged_comment.apply(lambda x: x.replace('<in>', '[IN]').replace('<out>', '[OUT]').replace('<other>', '[OTHER]'))\n",
    "ann_df.ref_expressions = ann_df.ref_expressions.apply(lambda x: [y.replace('<in>', '[IN]').replace('<out>', '[OUT]').replace('<other>', '[OTHER]') for y in x])\n",
    "ann_df.ref_tags = ann_df.ref_tags.apply(lambda x: [y.replace('<in>', '[IN]').replace('<out>', '[OUT]').replace('<other>', '[OTHER]') for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fb360f9-a9b9-4eb8-b02d-f3ee37055732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>tokenized_comment</th>\n",
       "      <th>tagged_comment</th>\n",
       "      <th>ref_expressions</th>\n",
       "      <th>ref_pos</th>\n",
       "      <th>ref_tags</th>\n",
       "      <th>user</th>\n",
       "      <th>confs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>s00mf8</td>\n",
       "      <td>hrzdn5h</td>\n",
       "      <td>[SENT] Watching this team is a damn roller - coaster</td>\n",
       "      <td>[SENT] Watching [IN] is a damn roller - coaster</td>\n",
       "      <td>[this team]</td>\n",
       "      <td>[(16, 25)]</td>\n",
       "      <td>[[IN]]</td>\n",
       "      <td>m</td>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>qi08vc</td>\n",
       "      <td>higjg47</td>\n",
       "      <td>[SENT] Maybe our Defense is legit</td>\n",
       "      <td>[SENT] Maybe [IN] [IN] is legit</td>\n",
       "      <td>[our, Defense]</td>\n",
       "      <td>[(13, 16), (17, 24)]</td>\n",
       "      <td>[[IN], [IN]]</td>\n",
       "      <td>a</td>\n",
       "      <td>[5, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>z6b1l1</td>\n",
       "      <td>iy0vudc</td>\n",
       "      <td>[SENT] The football gods giveth , the football gods taketh</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>a</td>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id comment_id  \\\n",
       "660   s00mf8    hrzdn5h   \n",
       "548   qi08vc    higjg47   \n",
       "1062  z6b1l1    iy0vudc   \n",
       "\n",
       "                                                tokenized_comment  \\\n",
       "660         [SENT] Watching this team is a damn roller - coaster    \n",
       "548                            [SENT] Maybe our Defense is legit    \n",
       "1062  [SENT] The football gods giveth , the football gods taketh    \n",
       "\n",
       "                                        tagged_comment ref_expressions  \\\n",
       "660   [SENT] Watching [IN] is a damn roller - coaster      [this team]   \n",
       "548                   [SENT] Maybe [IN] [IN] is legit   [our, Defense]   \n",
       "1062                                                                []   \n",
       "\n",
       "                   ref_pos      ref_tags user   confs  \n",
       "660             [(16, 25)]        [[IN]]    m     [3]  \n",
       "548   [(13, 16), (17, 24)]  [[IN], [IN]]    a  [5, 5]  \n",
       "1062                    []            []    a     [5]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6ae8c92-dbdb-49fa-b5e2-1a38069f4fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1499, 21)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4b0f773-8ab6-4c8c-b4b2-7c071cd713bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318, 21)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = gold[gold.split=='test']\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e36cb41-ee9f-44ff-a1b3-aeeea7164c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['m', 'a', 'k'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_df['user'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd7b5af-7993-473c-971d-92244644696b",
   "metadata": {},
   "source": [
    "## IAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23bc9385-7c07-452a-b477-9bfe419d9135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318, 21)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test[test.comment_id.isin(ann_df.comment_id.unique())]\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0049312a-c3a8-4748-b8d2-e4b446efdbc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>tokenized_comment</th>\n",
       "      <th>tagged_comment</th>\n",
       "      <th>ref_expressions</th>\n",
       "      <th>ref_pos</th>\n",
       "      <th>ref_tags</th>\n",
       "      <th>user</th>\n",
       "      <th>confs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yhbqwu</td>\n",
       "      <td>iueu4ch</td>\n",
       "      <td>[SENT] Dante has played well other then that offsides when were n't allowed to see !</td>\n",
       "      <td>[SENT] [IN] has played well other then that offsides when were n't allowed to see !</td>\n",
       "      <td>[Dante]</td>\n",
       "      <td>[(7, 12)]</td>\n",
       "      <td>[[IN]]</td>\n",
       "      <td>m</td>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q0ta6h</td>\n",
       "      <td>hfb1e8j</td>\n",
       "      <td>[SENT] I mean I like the idea of a top 10 pick but .... we 're about to be tied with the Jets here ..... it's bad</td>\n",
       "      <td>[SENT] I mean I like the idea of a top 10 pick but .... [IN] about to be tied with [OTHER] here ..... it's bad</td>\n",
       "      <td>[we 're, the Jets]</td>\n",
       "      <td>[(56, 62), (85, 93)]</td>\n",
       "      <td>[[IN], [OTHER]]</td>\n",
       "      <td>m</td>\n",
       "      <td>[5, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zudthn</td>\n",
       "      <td>j1iyyse</td>\n",
       "      <td>[SENT] I sometimes feel like we ’re just tanking these last games</td>\n",
       "      <td>[SENT] I sometimes feel like [IN] just tanking these last games</td>\n",
       "      <td>[we ’re]</td>\n",
       "      <td>[(29, 35)]</td>\n",
       "      <td>[[IN]]</td>\n",
       "      <td>m</td>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfujw5</td>\n",
       "      <td>hogvith</td>\n",
       "      <td>[SENT] And ESPN wonders why people tune into the Manningcast over their main broadcast , they suck</td>\n",
       "      <td>[SENT] And [OTHER] wonders why [OTHER] tune into [OTHER] over [OTHER] , [OTHER] suck</td>\n",
       "      <td>[ESPN, people, the Manningcast, their main broadcast, they]</td>\n",
       "      <td>[(11, 15), (28, 34), (45, 60), (66, 86), (89, 93)]</td>\n",
       "      <td>[[OTHER], [OTHER], [OTHER], [OTHER], [OTHER]]</td>\n",
       "      <td>m</td>\n",
       "      <td>[5, 5, 5, 5, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q5bp35</td>\n",
       "      <td>hg4pmv1</td>\n",
       "      <td>[SENT] Hurts is n't playing well , but this legitimately might be the worst game plan we 've seen in a long long time .</td>\n",
       "      <td>[SENT] [IN] is n't playing well , but this legitimately might be the worst game plan [IN] seen in a long long time .</td>\n",
       "      <td>[Hurts, we 've]</td>\n",
       "      <td>[(7, 12), (86, 92)]</td>\n",
       "      <td>[[IN], [IN]]</td>\n",
       "      <td>m</td>\n",
       "      <td>[5, 5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  post_id comment_id  \\\n",
       "0  yhbqwu    iueu4ch   \n",
       "1  q0ta6h    hfb1e8j   \n",
       "2  zudthn    j1iyyse   \n",
       "3  rfujw5    hogvith   \n",
       "4  q5bp35    hg4pmv1   \n",
       "\n",
       "                                                                                                          tokenized_comment  \\\n",
       "0                                     [SENT] Dante has played well other then that offsides when were n't allowed to see !    \n",
       "1        [SENT] I mean I like the idea of a top 10 pick but .... we 're about to be tied with the Jets here ..... it's bad    \n",
       "2                                                        [SENT] I sometimes feel like we ’re just tanking these last games    \n",
       "3                       [SENT] And ESPN wonders why people tune into the Manningcast over their main broadcast , they suck    \n",
       "4  [SENT] Hurts is n't playing well , but this legitimately might be the worst game plan we 've seen in a long long time .    \n",
       "\n",
       "                                                                                                          tagged_comment  \\\n",
       "0                                   [SENT] [IN] has played well other then that offsides when were n't allowed to see !    \n",
       "1        [SENT] I mean I like the idea of a top 10 pick but .... [IN] about to be tied with [OTHER] here ..... it's bad    \n",
       "2                                                       [SENT] I sometimes feel like [IN] just tanking these last games    \n",
       "3                                  [SENT] And [OTHER] wonders why [OTHER] tune into [OTHER] over [OTHER] , [OTHER] suck    \n",
       "4  [SENT] [IN] is n't playing well , but this legitimately might be the worst game plan [IN] seen in a long long time .    \n",
       "\n",
       "                                               ref_expressions  \\\n",
       "0                                                      [Dante]   \n",
       "1                                           [we 're, the Jets]   \n",
       "2                                                     [we ’re]   \n",
       "3  [ESPN, people, the Manningcast, their main broadcast, they]   \n",
       "4                                              [Hurts, we 've]   \n",
       "\n",
       "                                              ref_pos  \\\n",
       "0                                           [(7, 12)]   \n",
       "1                                [(56, 62), (85, 93)]   \n",
       "2                                          [(29, 35)]   \n",
       "3  [(11, 15), (28, 34), (45, 60), (66, 86), (89, 93)]   \n",
       "4                                 [(7, 12), (86, 92)]   \n",
       "\n",
       "                                        ref_tags user            confs  \n",
       "0                                         [[IN]]    m              [5]  \n",
       "1                                [[IN], [OTHER]]    m           [5, 5]  \n",
       "2                                         [[IN]]    m              [5]  \n",
       "3  [[OTHER], [OTHER], [OTHER], [OTHER], [OTHER]]    m  [5, 5, 5, 5, 5]  \n",
       "4                                   [[IN], [IN]]    m           [5, 5]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6859d99-24eb-4b1c-a052-753a9b0433d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6466666666666666, 0.004714045207910321)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_agrees = {x: [] for x in ['k', 'a', 'm']}\n",
    "conf_agrees = []\n",
    "conf_disagrees = []\n",
    "\n",
    "for i, row in test.iterrows():\n",
    "    comment_id = row.comment_id\n",
    "    ref_exps = row.ref_expressions\n",
    "    ref_tags = row.ref_tags\n",
    "    for user in user_agrees.keys():\n",
    "        new_row = ann_df.loc[((ann_df.comment_id==comment_id) & (ann_df.user==user))]\n",
    "        new_exps = new_row.ref_expressions.values[0]\n",
    "        new_tags = new_row.ref_tags.values[0]\n",
    "\n",
    "        if ((new_exps==ref_exps) and (new_tags==ref_tags)):\n",
    "            user_agrees[user].append(1)\n",
    "            conf_agrees += new_row.confs.values.tolist()\n",
    "        else:\n",
    "            min_overlap = min(len(ref_exps), len(new_exps))\n",
    "            if min_overlap==0:\n",
    "                # print(ref_exps, ref_tags, new_exps, new_tags, row.tokenized_comment.replace('[SENT]', ''))\n",
    "                user_agrees[user].append(0)\n",
    "                conf_disagrees += new_row.confs.values.tolist()\n",
    "                continue\n",
    "            count = 0\n",
    "            for i in range(0, min_overlap):\n",
    "                if ((SequenceMatcher(None, ref_exps[i], new_exps[i]).ratio()>0.5) and (ref_tags[i]==new_tags[i])):\n",
    "                    count += 1\n",
    "            # print(ref_exps, new_exps)\n",
    "            user_agrees[user].append(count/min_overlap)\n",
    "            conf_agrees += new_row.confs.values.tolist()\n",
    "total = test.shape[0]\n",
    "scores = [np.round(sum(user_agrees['k'])/total, 2), np.round(sum(user_agrees['a'])/total, 2), np.round(sum(user_agrees['m'])/total, 2)]\n",
    "np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f187cdbb-03d5-4180-bc02-e43ea0f3533a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.77, 4.46)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.mean(sum(conf_agrees, [])), 2), np.round(np.mean(sum(conf_disagrees, [])), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcf7174a-5176-42cf-9407-bdcb5c114df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.81, 1.22)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.std(sum(conf_agrees, [])), 2), np.round(np.std(sum(conf_disagrees, [])), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f880b0e1-a3e7-415b-ab9e-82f941103671",
   "metadata": {},
   "source": [
    "## Fleiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc10bb3e-6fd6-4bd1-8de3-8ea42e098a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = ['k', 'a', 'm']\n",
    "tag_map = {'[IN]': 1, '[OUT]': 2, '[OTHER]': 3}\n",
    "\n",
    "ratings_table = []\n",
    "\n",
    "for i, row in test.iterrows():\n",
    "    comment_id = row.comment_id\n",
    "    num_subjects = max(1, len(row.ref_expressions))\n",
    "\n",
    "    for ind in range(num_subjects):\n",
    "        rating_subject = []\n",
    "        for user in users:\n",
    "            new_row = ann_df.loc[((ann_df.comment_id==comment_id) & (ann_df.user==user))]\n",
    "            new_exps = new_row.ref_expressions.values[0]\n",
    "            new_tags = new_row.ref_tags.values[0]\n",
    "    \n",
    "            if new_exps == []:\n",
    "                rating_subject.append(0)\n",
    "            else:\n",
    "                if ind < len(new_tags):\n",
    "                    rating_subject.append(tag_map[new_tags[ind]])\n",
    "                else:\n",
    "                    rating_subject.append(0)\n",
    "        ratings_table.append(rating_subject)\n",
    "\n",
    "table, categories = aggregate_raters(ratings_table)\n",
    "np.round(fleiss_kappa(table),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13c5dfc0-d127-400f-970b-d03be80b94b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(954, 9)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_df_test = ann_df[ann_df['comment_id'].isin(test.comment_id.values)]\n",
    "ann_df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d73cd718-6fa9-4943-9878-2ae5b1e6146c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>tokenized_comment</th>\n",
       "      <th>tagged_comment</th>\n",
       "      <th>ref_expressions</th>\n",
       "      <th>ref_pos</th>\n",
       "      <th>ref_tags</th>\n",
       "      <th>user</th>\n",
       "      <th>confs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yhbqwu</td>\n",
       "      <td>iueu4ch</td>\n",
       "      <td>[SENT] Dante has played well other then that offsides when were n't allowed to see !</td>\n",
       "      <td>[SENT] [IN] has played well other then that offsides when were n't allowed to see !</td>\n",
       "      <td>[Dante]</td>\n",
       "      <td>[(7, 12)]</td>\n",
       "      <td>[[IN]]</td>\n",
       "      <td>m</td>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q0ta6h</td>\n",
       "      <td>hfb1e8j</td>\n",
       "      <td>[SENT] I mean I like the idea of a top 10 pick but .... we 're about to be tied with the Jets here ..... it's bad</td>\n",
       "      <td>[SENT] I mean I like the idea of a top 10 pick but .... [IN] about to be tied with [OTHER] here ..... it's bad</td>\n",
       "      <td>[we 're, the Jets]</td>\n",
       "      <td>[(56, 62), (85, 93)]</td>\n",
       "      <td>[[IN], [OTHER]]</td>\n",
       "      <td>m</td>\n",
       "      <td>[5, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zudthn</td>\n",
       "      <td>j1iyyse</td>\n",
       "      <td>[SENT] I sometimes feel like we ’re just tanking these last games</td>\n",
       "      <td>[SENT] I sometimes feel like [IN] just tanking these last games</td>\n",
       "      <td>[we ’re]</td>\n",
       "      <td>[(29, 35)]</td>\n",
       "      <td>[[IN]]</td>\n",
       "      <td>m</td>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfujw5</td>\n",
       "      <td>hogvith</td>\n",
       "      <td>[SENT] And ESPN wonders why people tune into the Manningcast over their main broadcast , they suck</td>\n",
       "      <td>[SENT] And [OTHER] wonders why [OTHER] tune into [OTHER] over [OTHER] , [OTHER] suck</td>\n",
       "      <td>[ESPN, people, the Manningcast, their main broadcast, they]</td>\n",
       "      <td>[(11, 15), (28, 34), (45, 60), (66, 86), (89, 93)]</td>\n",
       "      <td>[[OTHER], [OTHER], [OTHER], [OTHER], [OTHER]]</td>\n",
       "      <td>m</td>\n",
       "      <td>[5, 5, 5, 5, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q5bp35</td>\n",
       "      <td>hg4pmv1</td>\n",
       "      <td>[SENT] Hurts is n't playing well , but this legitimately might be the worst game plan we 've seen in a long long time .</td>\n",
       "      <td>[SENT] [IN] is n't playing well , but this legitimately might be the worst game plan [IN] seen in a long long time .</td>\n",
       "      <td>[Hurts, we 've]</td>\n",
       "      <td>[(7, 12), (86, 92)]</td>\n",
       "      <td>[[IN], [IN]]</td>\n",
       "      <td>m</td>\n",
       "      <td>[5, 5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  post_id comment_id  \\\n",
       "0  yhbqwu    iueu4ch   \n",
       "1  q0ta6h    hfb1e8j   \n",
       "2  zudthn    j1iyyse   \n",
       "3  rfujw5    hogvith   \n",
       "4  q5bp35    hg4pmv1   \n",
       "\n",
       "                                                                                                          tokenized_comment  \\\n",
       "0                                     [SENT] Dante has played well other then that offsides when were n't allowed to see !    \n",
       "1        [SENT] I mean I like the idea of a top 10 pick but .... we 're about to be tied with the Jets here ..... it's bad    \n",
       "2                                                        [SENT] I sometimes feel like we ’re just tanking these last games    \n",
       "3                       [SENT] And ESPN wonders why people tune into the Manningcast over their main broadcast , they suck    \n",
       "4  [SENT] Hurts is n't playing well , but this legitimately might be the worst game plan we 've seen in a long long time .    \n",
       "\n",
       "                                                                                                          tagged_comment  \\\n",
       "0                                   [SENT] [IN] has played well other then that offsides when were n't allowed to see !    \n",
       "1        [SENT] I mean I like the idea of a top 10 pick but .... [IN] about to be tied with [OTHER] here ..... it's bad    \n",
       "2                                                       [SENT] I sometimes feel like [IN] just tanking these last games    \n",
       "3                                  [SENT] And [OTHER] wonders why [OTHER] tune into [OTHER] over [OTHER] , [OTHER] suck    \n",
       "4  [SENT] [IN] is n't playing well , but this legitimately might be the worst game plan [IN] seen in a long long time .    \n",
       "\n",
       "                                               ref_expressions  \\\n",
       "0                                                      [Dante]   \n",
       "1                                           [we 're, the Jets]   \n",
       "2                                                     [we ’re]   \n",
       "3  [ESPN, people, the Manningcast, their main broadcast, they]   \n",
       "4                                              [Hurts, we 've]   \n",
       "\n",
       "                                              ref_pos  \\\n",
       "0                                           [(7, 12)]   \n",
       "1                                [(56, 62), (85, 93)]   \n",
       "2                                          [(29, 35)]   \n",
       "3  [(11, 15), (28, 34), (45, 60), (66, 86), (89, 93)]   \n",
       "4                                 [(7, 12), (86, 92)]   \n",
       "\n",
       "                                        ref_tags user            confs  \n",
       "0                                         [[IN]]    m              [5]  \n",
       "1                                [[IN], [OTHER]]    m           [5, 5]  \n",
       "2                                         [[IN]]    m              [5]  \n",
       "3  [[OTHER], [OTHER], [OTHER], [OTHER], [OTHER]]    m  [5, 5, 5, 5, 5]  \n",
       "4                                   [[IN], [IN]]    m           [5, 5]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22125aec-841b-417f-80ba-2b97b41e3a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_df.to_csv('../../../data/ann_data_full.tsv', sep='\\t', quoting=csv.QUOTE_NONE, escapechar=\"\\\\\", index=False, columns=['post_id', 'comment_id', 'user', 'tokenized_comment', 'tagged_comment', 'ref_expressions', 'ref_pos', 'ref_tags', 'confs'])\n",
    "ann_df_test.to_csv('../../../data/ann_data_test.tsv', sep='\\t', quoting=csv.QUOTE_NONE, escapechar=\"\\\\\", index=False, columns=['post_id', 'comment_id', 'user', 'tokenized_comment', 'tagged_comment', 'ref_expressions', 'ref_pos', 'ref_tags', 'confs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96161f96-c355-4a6e-bc5c-a8afb8769151",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_df.rename(columns={'user': 'annotator_id'}, inplace=True)\n",
    "ann_df.to_csv('../../../../intergroup-nfl/data/ann_data.tsv', sep='\\t', quoting=csv.QUOTE_NONE, escapechar=\"\\\\\", index=False, columns=['post_id', 'comment_id', 'annotator_id', 'tagged_comment', 'ref_expressions', 'ref_pos', 'ref_tags', 'confs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3737e9-3517-4698-ba44-ec890355daba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
